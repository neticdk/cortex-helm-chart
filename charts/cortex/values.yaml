image:
  repository: quay.io/cortexproject/cortex
  # -- Allows you to override the cortex version in this chart. Use at your own risk.
  tag: ""
  pullPolicy: IfNotPresent

  # -- Optionally specify an array of imagePullSecrets.
  # Secrets must be manually created in the namespace.
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
  pullSecrets: []

# -- Kubernetes cluster DNS domain
clusterDomain: cluster.local

tags:
  # -- Set to true to enable block storage memcached caching
  blocks-storage-memcached: false

ingress:
  enabled: false
  ingressClass:
    enabled: false
    name: "nginx"
  annotations: {}
  hosts:
    - host: chart-example.local
      paths:
        - /
  tls: []

serviceAccount:
  create: true
  name:
  annotations: {}
  automountServiceAccountToken: true

useConfigMap: false
useExternalConfig: false
externalConfigSecretName: 'secret-with-config.yaml'
externalConfigVersion: '0'

config:
  auth_enabled: true
  api:
    prometheus_http_prefix: '/prometheus'
    # -- Use GZIP compression for API responses. Some endpoints serve large YAML or JSON blobs
    # which can benefit from compression.
    response_compression_enabled: true
  ingester:
    lifecycler:
      # -- We don't want to join immediately, but wait a bit to see other ingesters and their tokens first.
      # It can take a while to have the full picture when using gossip
      join_after: 10s

      # -- To avoid generating same tokens by multiple ingesters, they can "observe" the ring for a while,
      # after putting their own tokens into it. This is only useful when using gossip, since multiple
      # ingesters joining at the same time can have conflicting tokens if they don't see each other yet.
      observe_period: 10s
      # -- Duration to sleep for before exiting, to ensure metrics are scraped.
      final_sleep: 30s
      num_tokens: 512

      ring:
        # -- Ingester replication factor per default is 3
        replication_factor: 3
        kvstore:
          store: consul
          consul:
            host: '{{ .Release.Name }}-consul-server:8500'
            # consistent_reads: true

  server:
    http_listen_port: 8080
    grpc_listen_port: 9095
    grpc_server_max_recv_msg_size: 104857600
    grpc_server_max_send_msg_size: 104857600
    grpc_server_max_concurrent_streams: 1000

  ingester_client:
    grpc_client_config:
      # Configure the client to allow messages up to 100MiB
      max_recv_msg_size: 104857600
      max_send_msg_size: 104857600
      grpc_compression: gzip

  # -- See https://github.com/cortexproject/cortex/blob/master/docs/configuration/config-file-reference.md#storage_config
  storage:
    engine: blocks
    index_queries_cache_config:
      memcached:
        # -- How long keys stay in the memcache
        expiration: 1h
      memcached_client:
        # -- Maximum time to wait before giving up on memcached requests.
        timeout: 1s
  blocks_storage:
    tsdb:
      dir: /data/tsdb
    bucket_store:
      sync_dir: /data/tsdb
      bucket_index:
        enabled: true

  # -- https://cortexmetrics.io/docs/configuration/configuration-file/#store_gateway_config
  store_gateway:
    sharding_enabled: false  # this is also default but allows for this to be used the templates

  distributor:
    # -- Distribute samples based on all labels, as opposed to solely by user and
    # metric name.
    shard_by_all_labels: true
    pool:
      health_check_ingesters: true

  memberlist:
    bind_port: 7946
    # -- the service name of the memberlist
    join_members: []
    ## add here the service name of the ingesters
    ## if using memberlist discovery, eg:
    #  - cortex-ingester-headless

  querier:
    active_query_tracker_dir: /data/cortex-active-query-tracker
    query_ingesters_within: 6h

  query_range:
    split_queries_by_interval: 24h
    align_queries_with_step: true
    cache_results: true
    results_cache:
      cache:
        memcached:
          expiration: 1h
        memcached_client:
          timeout: 1s

  ruler:
    enable_alertmanager_v2: true
    rule_path: /data/cortex-rules

  alertmanager:
    # -- Enable the experimental alertmanager config api.
    enable_api: false
    external_url: '/api/prom/alertmanager'
    # -- Type of backend to use to store alertmanager configs. Supported values are: "configdb", "gcs", "s3", "local". refer to: https://cortexmetrics.io/docs/configuration/configuration-file/#alertmanager_config
    storage: {}

  frontend:
    log_queries_longer_than: 10s

  compactor:
    data_dir: /data/cortex-compactor

  limits: {}
  # -- Enforce that every sample has a metric name
  # enforce_metric_name: true
  # reject_old_samples: true
  # reject_old_samples_max_age: 168h
  # max_query_lookback: 0s

runtimeconfigmap:
  # -- If true, a configmap for the `runtime_config` will be created.
  # If false, the configmap _must_ exist already on the cluster or pods will fail to create.
  create: true
  annotations: {}
  # -- https://cortexmetrics.io/docs/configuration/arguments/#runtime-configuration-file
  runtime_config: {}

rbac:
  create: true
  pspEnabled: true

alertmanager:
  enabled: true
  replicas: 1

  statefulSet:
    # -- If true, use a statefulset instead of a deployment for pod management.
    # This is useful for using a persistent volume for storing silences between restarts.
    enabled: false

  service:
    annotations: {}
    labels: {}

  serviceAccount:
    # -- "" disables the individual serviceAccount and uses the global serviceAccount for that component
    name: ""

  serviceMonitor:
    enabled: false
    additionalLabels: {}
    relabelings: []
    metricRelabelings: []
    # -- Additional endpoint configuration https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#endpoint
    extraEndpointSpec: {}

  resources: {}

  # -- Additional Cortex container arguments, e.g. log level (debug, info, warn, error)
  extraArgs: {}

  # -- Pod Labels
  podLabels: {}

  # -- Pod Annotations
  podAnnotations: {}
  #  prometheus.io/scrape: 'true'
  #  prometheus.io/port: 'http-metrics'

  nodeSelector: {}
  affinity: {}
  annotations: {}

  persistentVolume:
    # -- If true and alertmanager.statefulSet.enabled is true,
    # Alertmanager will create/use a Persistent Volume Claim
    # If false, use emptyDir
    enabled: true

    # -- Alertmanager data Persistent Volume Claim annotations
    annotations: {}

    # -- Alertmanager data Persistent Volume access modes
    # Must match those of existing PV or dynamic provisioner
    # Ref: http://kubernetes.io/docs/user-guide/persistent-volumes/
    accessModes:
      - ReadWriteOnce

    # -- Alertmanager data Persistent Volume size
    size: 2Gi

    # -- Subdirectory of Alertmanager data Persistent Volume to mount
    # Useful if the volume's root directory is not empty
    subPath: ''

    # -- Alertmanager data Persistent Volume Storage Class
    # If defined, storageClassName: <storageClass>
    # If set to "-", storageClassName: "", which disables dynamic provisioning
    # If undefined (the default) or set to null, no storageClassName spec is
    # set, choosing the default provisioner.
    storageClass: null

  startupProbe:
    httpGet:
      path: /ready
      port: http-metrics
    failureThreshold: 10
  livenessProbe:
    httpGet:
      path: /ready
      port: http-metrics
  readinessProbe:
    httpGet:
      path: /ready
      port: http-metrics

  securityContext: {}

  containerSecurityContext:
    readOnlyRootFilesystem: true

  # -- Tolerations for pod assignment
  # ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  tolerations: []

  # -- If not set then a PodDisruptionBudget will not be created
  podDisruptionBudget:
    maxUnavailable: 1

  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 0
      maxUnavailable: 1
  statefulStrategy:
    type: RollingUpdate

  terminationGracePeriodSeconds: 60

  # -- Init containers to be added to the cortex pod.
  initContainers: []

  # -- Additional containers to be added to the cortex pod.
  extraContainers: []

  # -- Additional volumes to the cortex pod.
  extraVolumes: []

  # -- Extra volume mounts that will be added to the cortex container
  extraVolumeMounts: []

  # -- Additional ports to the cortex services. Useful to expose extra container ports.
  extraPorts: []

  # -- Extra env variables to pass to the cortex container
  env: []

  # -- Sidecars that collect the configmaps with specified label and stores the included files them into the respective folders
  sidecar:
    image:
      repository: quay.io/kiwigrid/k8s-sidecar
      tag: 1.10.7
      sha: ""
    imagePullPolicy: IfNotPresent
    resources: {}
    # -- skipTlsVerify Set to true to skip tls verification for kube api calls
    skipTlsVerify: false
    enableUniqueFilenames: false
    enabled: false
    label: cortex_alertmanager
    watchMethod: null
    labelValue: null
    folder: /data
    defaultFolderName: null
    searchNamespace: null
    folderAnnotation: null
    containerSecurityContext:
      readOnlyRootFilesystem: true

distributor:
  replicas: 2

  service:
    annotations: {}
    labels: {}

  serviceAccount:
    # -- "" disables the individual serviceAccount and uses the global serviceAccount for that component
    name: ""

  serviceMonitor:
    enabled: false
    additionalLabels: {}
    relabelings: []
    metricRelabelings: []
    # -- Additional endpoint configuration https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#endpoint
    extraEndpointSpec: {}

  resources: {}

  # -- Additional Cortex container arguments, e.g. log.level (debug, info, warn, error)
  extraArgs: {}

  # -- Pod Labels
  podLabels: {}

  # -- Pod Annotations
  podAnnotations: {}
  #  prometheus.io/scrape: 'true'
  #  prometheus.io/port: 'http-metrics'

  nodeSelector: {}
  affinity:
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            labelSelector:
              matchExpressions:
                - key: app.kubernetes.io/component
                  operator: In
                  values:
                    - distributor
            topologyKey: 'kubernetes.io/hostname'

  annotations: {}

  autoscaling:
    # -- Creates a HorizontalPodAutoscaler for the distributor pods.
    enabled: false
    minReplicas: 2
    maxReplicas: 30
    targetCPUUtilizationPercentage: 80
    targetMemoryUtilizationPercentage: 0  # 80
    # -- Ref: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/#support-for-configurable-scaling-behavior
    behavior: {}

  persistentVolume:
    subPath:

  startupProbe:
    httpGet:
      path: /ready
      port: http-metrics
    failureThreshold: 10
  livenessProbe:
    httpGet:
      path: /ready
      port: http-metrics
  readinessProbe:
    httpGet:
      path: /ready
      port: http-metrics

  securityContext: {}

  containerSecurityContext:
    readOnlyRootFilesystem: true

  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 0
      maxUnavailable: 1

  terminationGracePeriodSeconds: 60

  tolerations: []

  podDisruptionBudget:
    maxUnavailable: 1

  initContainers: []
  extraContainers: []
  extraVolumes: []
  extraVolumeMounts: []
  extraPorts: []
  env: []
  lifecycle: {}

ingester:
  replicas: 3

  statefulSet:
    # -- If true, use a statefulset instead of a deployment for pod management.
    # This is useful when using WAL
    enabled: false
    # -- ref: https://cortexmetrics.io/docs/guides/ingesters-scaling-up-and-down/#scaling-down and https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#pod-management-policies for scaledown details
    podManagementPolicy: OrderedReady

  service:
    annotations: {}
    labels: {}

  serviceAccount:
    name:

  serviceMonitor:
    enabled: false
    additionalLabels: {}
    relabelings: []
    metricRelabelings: []
    # -- Additional endpoint configuration https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#endpoint
    extraEndpointSpec: {}

  resources: {}

  # -- Additional Cortex container arguments, e.g. log.level (debug, info, warn, error)
  extraArgs: {}

  # -- Pod Labels
  podLabels: {}

  # -- Pod Annotations
  podAnnotations: {}
  #  prometheus.io/scrape: 'true'
  #  prometheus.io/port: 'http-metrics'

  nodeSelector: {}
  affinity:
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            labelSelector:
              matchExpressions:
                - key: app.kubernetes.io/component
                  operator: In
                  values:
                    - ingester
            topologyKey: 'kubernetes.io/hostname'

  annotations: {}

  autoscaling:
    enabled: false
    minReplicas: 3
    maxReplicas: 30
    targetMemoryUtilizationPercentage: 80
    behavior:
      scaleDown:
        # -- see https://cortexmetrics.io/docs/guides/ingesters-scaling-up-and-down/#scaling-down for scaledown details
        policies:
          - type: Pods
            value: 1
            # set to no less than 2x the maximum between -blocks-storage.bucket-store.sync-interval and -compactor.cleanup-interval
            periodSeconds: 1800
        # -- uses metrics from the past 1h to make scaleDown decisions
        stabilizationWindowSeconds: 3600
      scaleUp:
        # -- This default scaleup policy allows adding 1 pod every 30 minutes.
        # Ref: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/#support-for-configurable-scaling-behavior
        policies:
          - type: Pods
            value: 1
            periodSeconds: 1800

  lifecycle:
    # -- The /shutdown preStop hook is recommended as part of the ingester
    # scaledown process, but can be removed to optimize rolling restarts in
    # instances that will never be scaled down or when using chunks storage
    # with WAL disabled.
    # https://cortexmetrics.io/docs/guides/ingesters-scaling-up-and-down/#scaling-down
    preStop:
      httpGet:
        path: "/ingester/shutdown"
        port: http-metrics

  persistentVolume:
    # -- If true and ingester.statefulSet.enabled is true,
    # Ingester will create/use a Persistent Volume Claim
    # If false, use emptyDir
    enabled: true

    # -- Ingester data Persistent Volume Claim annotations
    annotations: {}

    # -- Ingester data Persistent Volume access modes
    # Must match those of existing PV or dynamic provisioner
    # Ref: http://kubernetes.io/docs/user-guide/persistent-volumes/
    accessModes:
      - ReadWriteOnce

    # -- Ingester data Persistent Volume size
    size: 2Gi

    # -- Subdirectory of Ingester data Persistent Volume to mount
    # Useful if the volume's root directory is not empty
    subPath: ''

    # -- Ingester data Persistent Volume Storage Class
    # If defined, storageClassName: <storageClass>
    # If set to "-", storageClassName: "", which disables dynamic provisioning
    # If undefined (the default) or set to null, no storageClassName spec is
    # set, choosing the default provisioner.
    storageClass: null

  # -- Startup/liveness probes for ingesters are not recommended.
  #  Ref: https://cortexmetrics.io/docs/guides/running-cortex-on-kubernetes/#take-extra-care-with-ingesters
  startupProbe: {}

  # -- Startup/liveness probes for ingesters are not recommended - see production documentation.
  #  Ref: https://cortexmetrics.io/docs/guides/running-cortex-on-kubernetes/#take-extra-care-with-ingesters
  livenessProbe: {}

  readinessProbe:
    httpGet:
      path: /ready
      port: http-metrics

  securityContext: {}

  containerSecurityContext:
    readOnlyRootFilesystem: true

  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 0
      maxUnavailable: 1
  statefulStrategy:
    type: RollingUpdate

  terminationGracePeriodSeconds: 2400

  tolerations: []

  podDisruptionBudget:
    maxUnavailable: 1

  initContainers: []
  extraContainers: []
  extraVolumes: []
  extraVolumeMounts: []
  extraPorts: []
  env: []

ruler:
  enabled: true
  replicas: 1

  service:
    annotations: {}
    labels: {}

  serviceAccount:
    # -- "" disables the individual serviceAccount and uses the global serviceAccount for that component
    name: ""

  serviceMonitor:
    enabled: false
    additionalLabels: {}
    relabelings: []
    metricRelabelings: []
    # -- Additional endpoint configuration https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#endpoint
    extraEndpointSpec: {}

  resources: {}

  # -- Additional Cortex container arguments, e.g. log.level (debug, info, warn, error)
  extraArgs: {}

  # -- Pod Labels
  podLabels: {}

  # -- Pod Annotations
  podAnnotations: {}
  #  prometheus.io/scrape: 'true'
  #  prometheus.io/port: 'http-metrics'

  nodeSelector: {}
  affinity: {}
  annotations: {}
  persistentVolume:
    subPath:

  startupProbe:
    httpGet:
      path: /ready
      port: http-metrics
    failureThreshold: 10
  livenessProbe:
    httpGet:
      path: /ready
      port: http-metrics
  readinessProbe:
    httpGet:
      path: /ready
      port: http-metrics

  securityContext: {}

  containerSecurityContext:
    readOnlyRootFilesystem: true

  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 0
      maxUnavailable: 1

  terminationGracePeriodSeconds: 180

  tolerations: []

  podDisruptionBudget:
    maxUnavailable: 1

  initContainers: []
  extraContainers: []
  extraVolumes: []
  extraVolumeMounts: []
  extraPorts: []
  env: []
  # -- allow configuring rules via configmap. ref: https://cortexproject.github.io/cortex-helm-chart/guides/configure_rules_via_configmap.html
  directories: {}

  # -- Sidecars that collect the configmaps with specified label and stores the included files them into the respective folders
  sidecar:
    image:
      repository: quay.io/kiwigrid/k8s-sidecar
      tag: 1.10.7
      sha: ""
    imagePullPolicy: IfNotPresent
    resources: {}
    #   limits:
    #     cpu: 100m
    #     memory: 100Mi
    #   requests:
    #     cpu: 50m
    #     memory: 50Mi
    # skipTlsVerify Set to true to skip tls verification for kube api calls
    # skipTlsVerify: true
    enableUniqueFilenames: false
    enabled: false
    # -- label that the configmaps with rules are marked with
    label: cortex_rules
    watchMethod: null
    # -- value of label that the configmaps with rules are set to
    labelValue: null
    # -- folder in the pod that should hold the collected rules (unless `defaultFolderName` is set)
    folder: /tmp/rules
    # -- The default folder name, it will create a subfolder under the `folder` and put rules in there instead
    defaultFolderName: null
    # -- If specified, the sidecar will search for rules config-maps inside this namespace.
    # Otherwise the namespace in which the sidecar is running will be used.
    # It's also possible to specify ALL to search in all namespaces
    searchNamespace: null
    # -- If specified, the sidecar will look for annotation with this name to create folder and put graph here.
    # You can use this parameter together with `provider.foldersFromFilesStructure`to annotate configmaps and create folder structure.
    folderAnnotation: null
    containerSecurityContext:
      readOnlyRootFilesystem: true

querier:
  replicas: 2

  service:
    annotations: {}
    labels: {}

  serviceAccount:
    # -- "" disables the individual serviceAccount and uses the global serviceAccount for that component
    name: ""

  serviceMonitor:
    enabled: false
    additionalLabels: {}
    relabelings: []
    metricRelabelings: []
    # -- Additional endpoint configuration https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#endpoint
    extraEndpointSpec: {}

  resources: {}

  # -- Additional Cortex container arguments, e.g. log.level (debug, info, warn, error)
  extraArgs: {}

  # -- Pod Labels
  podLabels: {}

  # -- Pod Annotations
  podAnnotations: {}
  #  prometheus.io/scrape: 'true'
  #  prometheus.io/port: 'http-metrics'

  nodeSelector: {}
  affinity: {}
  #  podAntiAffinity:
  #    preferredDuringSchedulingIgnoredDuringExecution:
  #      - weight: 100
  #        podAffinityTerm:
  #          labelSelector:
  #            matchExpressions:
  #              - key: target
  #                operator: In
  #                values:
  #                  - querier
  #          topologyKey: 'kubernetes.io/hostname'

  annotations: {}

  autoscaling:
    # -- Creates a HorizontalPodAutoscaler for the querier pods.
    enabled: false
    minReplicas: 2
    maxReplicas: 30
    targetCPUUtilizationPercentage: 80
    targetMemoryUtilizationPercentage: 0  # 80
    # -- Ref: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/#support-for-configurable-scaling-behavior
    behavior: {}

  persistentVolume:
    subPath:

  startupProbe:
    httpGet:
      path: /ready
      port: http-metrics
    failureThreshold: 10
  livenessProbe:
    httpGet:
      path: /ready
      port: http-metrics
  readinessProbe:
    httpGet:
      path: /ready
      port: http-metrics

  securityContext: {}

  containerSecurityContext:
    readOnlyRootFilesystem: true

  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 0
      maxUnavailable: 1

  terminationGracePeriodSeconds: 180

  tolerations: []

  podDisruptionBudget:
    maxUnavailable: 1

  initContainers: []
  extraContainers: []
  extraVolumes: []
  extraVolumeMounts: []
  extraPorts: []
  env: []
  lifecycle: {}

query_frontend:
  replicas: 2

  service:
    annotations: {}
    labels: {}

  serviceAccount:
    # -- "" disables the individual serviceAccount and uses the global serviceAccount for that component
    name: ""

  serviceMonitor:
    enabled: false
    additionalLabels: {}
    relabelings: []
    metricRelabelings: []
    # -- Additional endpoint configuration https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#endpoint
    extraEndpointSpec: {}

  resources: {}

  # -- Additional Cortex container arguments, e.g. log.level (debug, info, warn, error)
  extraArgs: {}

  # -- Pod Labels
  podLabels: {}

  # -- Pod Annotations
  podAnnotations: {}
  #  prometheus.io/scrape: 'true'
  #  prometheus.io/port: 'http-metrics'

  nodeSelector: {}
  affinity: {}
  #  podAntiAffinity:
  #    preferredDuringSchedulingIgnoredDuringExecution:
  #      - weight: 100
  #        podAffinityTerm:
  #          labelSelector:
  #            matchExpressions:
  #              - key: target
  #                operator: In
  #                values:
  #                  - query-frontend
  #          topologyKey: 'kubernetes.io/hostname'

  annotations: {}
  persistentVolume:
    subPath:

  startupProbe:
    httpGet:
      path: /ready
      port: http-metrics
    failureThreshold: 10
  livenessProbe:
    httpGet:
      path: /ready
      port: http-metrics
  readinessProbe:
    httpGet:
      path: /ready
      port: http-metrics

  securityContext: {}
  containerSecurityContext:
    readOnlyRootFilesystem: true

  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 0
      maxUnavailable: 1

  terminationGracePeriodSeconds: 180

  tolerations: []

  podDisruptionBudget:
    maxUnavailable: 1

  initContainers: []
  extraContainers: []
  extraVolumes: []
  extraVolumeMounts: []
  extraPorts: []
  env: []
  lifecycle: {}

table_manager:
  replicas: 1

  service:
    annotations: {}
    labels: {}

  serviceAccount:
    # -- "" disables the individual serviceAccount and uses the global serviceAccount for that component
    name: ""

  serviceMonitor:
    enabled: false
    additionalLabels: {}
    relabelings: []
    metricRelabelings: []
    # -- Additional endpoint configuration https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#endpoint
    extraEndpointSpec: {}

  resources: {}

  # -- Additional Cortex container arguments, e.g. log.level (debug, info, warn, error)
  extraArgs: {}

  # -- Pod Labels
  podLabels: {}

  # -- Pod Annotations
  podAnnotations: {}
  #  prometheus.io/scrape: 'true'
  #  prometheus.io/port: 'http-metrics'

  nodeSelector: {}
  affinity: {}
  annotations: {}
  persistentVolume:
    subPath:

  startupProbe:
    httpGet:
      path: /ready
      port: http-metrics
    failureThreshold: 10
  livenessProbe:
    httpGet:
      path: /ready
      port: http-metrics
  readinessProbe:
    httpGet:
      path: /ready
      port: http-metrics

  securityContext: {}

  containerSecurityContext:
    readOnlyRootFilesystem: true

  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 0
      maxUnavailable: 1

  terminationGracePeriodSeconds: 180

  tolerations: []

  podDisruptionBudget:
    maxUnavailable: 1

  initContainers: []
  extraContainers: []
  extraVolumes: []
  extraVolumeMounts: []
  extraPorts: []
  env: []

configs:
  enabled: false
  replicas: 1

  service:
    annotations: {}
    labels: {}

  serviceAccount:
    # -- "" disables the individual serviceAccount and uses the global serviceAccount for that component
    name: ""

  serviceMonitor:
    enabled: false
    additionalLabels: {}
    relabelings: []
    metricRelabelings: []
    # -- Additional endpoint configuration https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#endpoint
    extraEndpointSpec: {}

  resources: {}

  # -- Additional Cortex container arguments, e.g. log.level (debug, info, warn, error)
  extraArgs: {}

  # -- Pod Labels
  podLabels: {}

  # -- Pod Annotations
  podAnnotations: {}
  #  prometheus.io/scrape: 'true'
  #  prometheus.io/port: 'http-metrics'

  nodeSelector: {}
  affinity: {}
  annotations: {}
  persistentVolume:
    subPath:

  startupProbe:
    httpGet:
      path: /ready
      port: http-metrics
    failureThreshold: 10
  livenessProbe:
    httpGet:
      path: /ready
      port: http-metrics
  readinessProbe:
    httpGet:
      path: /ready
      port: http-metrics

  securityContext: {}

  containerSecurityContext:
    readOnlyRootFilesystem: true

  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 0
      maxUnavailable: 1

  terminationGracePeriodSeconds: 180

  tolerations: []

  podDisruptionBudget:
    maxUnavailable: 1

  initContainers: []
  extraContainers: []
  extraVolumes: []
  extraVolumeMounts: []
  extraPorts: []
  env: []

nginx:
  enabled: true
  replicas: 2
  http_listen_port: 8080
  config:
    dnsResolver: kube-dns.kube-system.svc.cluster.local
    # -- ref: http://nginx.org/en/docs/http/ngx_http_core_module.html#client_max_body_size
    client_max_body_size: 1M
    # -- arbitrary snippet to inject in the http { } section of the nginx config
    httpSnippet: ""
    # -- arbitrary snippet to inject in the top section of the nginx config
    mainSnippet: ""
    # -- arbitrary snippet to inject in the server { } section of the nginx config
    serverSnippet: ""
    setHeaders: {}
    # -- (optional) List of [auth tenants](https://cortexmetrics.io/docs/guides/auth/) to set in the nginx config
    auth_orgs: []
    # -- (optional) Name of basic auth secret.
    # In order to use this option, a secret with htpasswd formatted contents at
    # the key ".htpasswd" must exist. For example:
    #
    #   apiVersion: v1
    #   kind: Secret
    #   metadata:
    #     name: my-secret
    #     namespace: <same as cortex installation>
    #   stringData:
    #     .htpasswd: |
    #       user1:$apr1$/woC1jnP$KAh0SsVn5qeSMjTtn0E9Q0
    #       user2:$apr1$QdR8fNLT$vbCEEzDj7LyqCMyNpSoBh/
    #
    # Please note that the use of basic auth will not identify organizations
    # the way X-Scope-OrgID does. Thus, the use of basic auth alone will not
    # prevent one tenant from viewing the metrics of another. To ensure tenants
    # are scoped appropriately, explicitly set the `X-Scope-OrgID` header
    # in the nginx config. Example
    #   setHeaders:
    #     X-Scope-OrgID: $remote_user
    basicAuthSecretName: ""

  image:
    repository: nginx
    tag: 1.21
    pullPolicy: IfNotPresent

  service:
    type: ClusterIP
    annotations: {}
    labels: {}

  serviceAccount:
    # -- "" disables the individual serviceAccount and uses the global serviceAccount for that component
    name: ""

  resources: {}

  # -- Additional Cortex container arguments, e.g. log.level (debug, info, warn, error)
  extraArgs: {}

  # -- Pod Labels
  podLabels: {}

  # -- Pod Annotations
  podAnnotations: {}
  #  prometheus.io/scrape: 'true'
  #  prometheus.io/port: 'http-metrics'

  nodeSelector: {}
  affinity: {}
  annotations: {}
  persistentVolume:
    subPath:

  startupProbe:
    httpGet:
      path: /healthz
      port: http-metrics
    failureThreshold: 10
  livenessProbe:
    httpGet:
      path: /healthz
      port: http-metrics
  readinessProbe:
    httpGet:
      path: /healthz
      port: http-metrics

  securityContext: {}

  containerSecurityContext:
    readOnlyRootFilesystem: false

  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 0
      maxUnavailable: 1

  terminationGracePeriodSeconds: 10

  tolerations: []

  podDisruptionBudget:
    maxUnavailable: 1

  initContainers: []
  extraContainers: []
  extraVolumes: []
  extraVolumeMounts: []
  extraPorts: []
  env: []

  autoscaling:
    # -- Creates a HorizontalPodAutoscaler for the nginx pods.
    enabled: false
    minReplicas: 2
    maxReplicas: 30
    targetCPUUtilizationPercentage: 80
    targetMemoryUtilizationPercentage: 0  # 80
    # -- Ref: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/#support-for-configurable-scaling-behavior
    behavior: {}

store_gateway:
  replicas: 1

  service:
    annotations: {}
    labels: {}

  serviceAccount:
    # -- "" disables the individual serviceAccount and uses the global serviceAccount for that component
    name: ""

  serviceMonitor:
    enabled: false
    additionalLabels: {}
    relabelings: []
    metricRelabelings: []
    # -- Additional endpoint configuration https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#endpoint
    extraEndpointSpec: {}

  resources: {}

  # -- Additional Cortex container arguments, e.g. log.level (debug, info, warn, error)
  extraArgs: {}

  # -- Pod Labels
  podLabels: {}

  # -- Pod Annotations
  podAnnotations: {}
  #  prometheus.io/scrape: 'true'
  #  prometheus.io/port: 'http-metrics'

  nodeSelector: {}
  affinity:
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            labelSelector:
              matchExpressions:
                - key: app.kubernetes.io/component
                  operator: In
                  values:
                    - store-gateway
            topologyKey: 'kubernetes.io/hostname'

  annotations: {}

  persistentVolume:
    # -- If true Store-gateway will create/use a Persistent Volume Claim
    # If false, use emptyDir
    enabled: true

    # -- Store-gateway data Persistent Volume Claim annotations
    annotations: {}

    # -- Store-gateway data Persistent Volume access modes
    # Must match those of existing PV or dynamic provisioner
    # Ref: http://kubernetes.io/docs/user-guide/persistent-volumes/
    accessModes:
      - ReadWriteOnce

    # -- Store-gateway data Persistent Volume size
    size: 2Gi

    # -- Subdirectory of Store-gateway data Persistent Volume to mount
    # Useful if the volume's root directory is not empty
    subPath: ''

    # -- Store-gateway data Persistent Volume Storage Class
    # If defined, storageClassName: <storageClass>
    # If set to "-", storageClassName: "", which disables dynamic provisioning
    # If undefined (the default) or set to null, no storageClassName spec is
    # set, choosing the default provisioner.
    storageClass: null

  startupProbe:
    failureThreshold: 60
    initialDelaySeconds: 120
    periodSeconds: 30
    httpGet:
      path: /ready
      port: http-metrics
      scheme: HTTP
  livenessProbe:
    httpGet:
      path: /ready
      port: http-metrics
      scheme: HTTP
  readinessProbe:
    httpGet:
      path: /ready
      port: http-metrics

  securityContext: {}

  containerSecurityContext:
    readOnlyRootFilesystem: true

  strategy:
    type: RollingUpdate

  terminationGracePeriodSeconds: 240

  tolerations: []

  podDisruptionBudget:
    maxUnavailable: 1

  initContainers: []
  extraContainers: []
  extraVolumes: []
  extraVolumeMounts: []
  extraPorts: []
  env: []

compactor:
  enabled: true
  replicas: 2

  service:
    annotations: {}
    labels: {}

  serviceAccount:
    # -- "" disables the individual serviceAccount and uses the global serviceAccount for that component
    name: ""

  serviceMonitor:
    enabled: false
    additionalLabels: {}
    relabelings: []
    metricRelabelings: []
    # -- Additional endpoint configuration https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#endpoint
    extraEndpointSpec: {}

  resources: {}

  # -- Additional Cortex container arguments, e.g. log.level (debug, info, warn, error)
  extraArgs: {}

  # -- Pod Labels
  podLabels: {}

  # -- Pod Annotations
  podAnnotations: {}
  #  prometheus.io/scrape: 'true'
  #  prometheus.io/port: 'http-metrics'

  nodeSelector: {}
  affinity:
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            labelSelector:
              matchExpressions:
                - key: app.kubernetes.io/component
                  operator: In
                  values:
                    - compactor
            topologyKey: 'kubernetes.io/hostname'

  annotations: {}

  persistentVolume:
    # -- If true compactor will create/use a Persistent Volume Claim
    # If false, use emptyDir
    enabled: true

    # -- compactor data Persistent Volume Claim annotations
    annotations: {}

    # -- compactor data Persistent Volume access modes
    # Must match those of existing PV or dynamic provisioner
    # Ref: http://kubernetes.io/docs/user-guide/persistent-volumes/
    accessModes:
      - ReadWriteOnce

    # compactor data Persistent Volume size
    size: 2Gi

    # -- Subdirectory of compactor data Persistent Volume to mount
    # Useful if the volume's root directory is not empty
    subPath: ''

    # -- compactor data Persistent Volume Storage Class
    # If defined, storageClassName: <storageClass>
    # If set to "-", storageClassName: "", which disables dynamic provisioning
    # If undefined (the default) or set to null, no storageClassName spec is
    # set, choosing the default provisioner.
    storageClass: null

  startupProbe:
    failureThreshold: 60
    initialDelaySeconds: 120
    periodSeconds: 30
    httpGet:
      path: /ready
      port: http-metrics
      scheme: HTTP
  livenessProbe:
    httpGet:
      path: /ready
      port: http-metrics
      scheme: HTTP
  readinessProbe:
    httpGet:
      path: /ready
      port: http-metrics

  securityContext: {}
  containerSecurityContext:
    readOnlyRootFilesystem: true

  strategy:
    type: RollingUpdate

  terminationGracePeriodSeconds: 240

  tolerations: []

  podDisruptionBudget:
    maxUnavailable: 1

  initContainers: []
  extraContainers: []
  extraVolumes: []
  extraVolumeMounts: []
  extraPorts: []
  env: []

# -- chunk caching for legacy chunk storage engine
memcached:
  enabled: false
  architecture: "high-availability"
  replicaCount: 2
  resources:
    requests:
      memory: 1329Mi
      cpu: 500m
    limits:
      memory: 1536Mi
  args:
    - /run.sh
    - -m 1024
    - -o
    - modern
    - -I 1m
    - -c 1024
    - -t 4
  metrics:
    enabled: true
    serviceMonitor:
      enabled: false

# -- index read caching for legacy chunk storage engine
memcached-index-read:
  enabled: false
  architecture: "high-availability"
  replicaCount: 2
  resources:
    requests:
      memory: 1329Mi
      cpu: 500m
    limits:
      memory: 1536Mi
  args:
    - /run.sh
    - -m 1024
    - -o
    - modern
    - -I 1m
    - -c 1024
    - -t 4
  metrics:
    enabled: true
    serviceMonitor:
      enabled: false

# -- index write caching for legacy chunk storage engine
memcached-index-write:
  enabled: false
  architecture: "high-availability"
  replicaCount: 2
  resources:
    requests:
      memory: 1329Mi
      cpu: 500m
    limits:
      memory: 1536Mi
  args:
    - /run.sh
    - -m 1024
    - -o
    - modern
    - -I 1m
    - -c 1024
    - -t 4
  metrics:
    enabled: true
    serviceMonitor:
      enabled: false

memcached-frontend:
  enabled: false
  architecture: "high-availability"
  replicaCount: 2
  args:
    - /run.sh
    - -m 1024
    - -o
    - modern
    - -I 1m
    - -c 1024
    - -t 32
  resources:
    requests:
      memory: 1329Mi
      cpu: 500m
    limits:
      memory: 1536Mi
  metrics:
    enabled: true
    serviceMonitor:
      enabled: false

memcached-index:
  # enabled/disabled via the tags.blocks-storage-memcached boolean
  architecture: "high-availability"
  replicaCount: 2
  args:
    - /run.sh
    - -m 1024
    - -o
    - modern
    - -I 16m
    - -c 1024
    - -t 32
  resources:
    requests:
      memory: 1329Mi
      cpu: 500m
    limits:
      memory: 1536Mi
  metrics:
    enabled: true
    serviceMonitor:
      enabled: false

memcached-chunks:
  # enabled/disabled via the tags.blocks-storage-memcached boolean
  architecture: "high-availability"
  replicaCount: 2
  args:
    - /run.sh
    - -m 6144
    - -o
    - modern
    - -I 1m
    - -c 4096
    - -t 32
  resources:
    requests:
      memory: 2048Mi
      cpu: 500m
    limits:
      memory: 7680Mi
  metrics:
    enabled: true
    serviceMonitor:
      enabled: false

memcached-metadata:
  # enabled/disabled via the tags.blocks-storage-memcached boolean
  architecture: "high-availability"
  replicaCount: 2
  args:
    - /run.sh
    - -m 512
    - -o
    - modern
    - -I 1m
    - -c 1024
    - -t 32
  resources:
    requests:
      memory: 715Mi
      cpu: 500m
    limits:
      memory: 768Mi
  metrics:
    enabled: true
    serviceMonitor:
      enabled: false

configsdb_postgresql:
  enabled: false
  uri:
  auth:
    password:
    existing_secret:
      name:
      key:

consul:
  enabled: false
  client:
    enabled: false
